# Know³-RAG
code of Know³-RAG
## Start
Most environments can be installed:

```bash
 pip install -r requirements.txt
```
For entity linking, please see [Spacy Entity Linker](https://github.com/egerber/spaCy-entity-linker) to install local knowledge base.

For KGE model, please see [kge](https://github.com/uma-pi1/kge) to download the model and run the codes.

## Datasets
See `datasets`
## Code
*The code is a mess and we'll simplify it in a few months.*

core code of Know³-RAG is in `code`. you need to pay attention:
#### main.py: 
All moudle based on LLM, which you can run as:
```bash
python code/main.py \
    --dataset_name dataset_name \
    --dataset_path /path/to/your/datasets/ \
    --line \  # we process the data in jsonl format
    --model_name model_name \  
    # if you select 'api', it will output (user, assistant) pair and you can then run it for any models
    --model_path /path/to/your/model \
    --exp_name output_file_name \
    --test_input input_test_file_name \
    --dev_input input_dev_file_name \
```
Some important arguments you should know:
- --rag: question answer
- --generate_reference: LLM knowledge generation  
- --local_check: relevance check
- --extract_triple: extract triple from text, used in triple factual check
- --generate_question: query_generation

#### card_infer.py:
Knowledge generation of smaller model from [Knowledge Card](https://github.com/BunsenFeng/Knowledge_Card), which you can run as:
```bash
python code/card_infer.py \
    --task entity \ 
    # question for raw query. entity for KG-enhanced query.
    --model_path /path/to/knowledge/model \
    --device 7 \
    --k 1 \
    --input_file /path/to/input/file \
    --output_file /path/to/output/file
```
You can visit [Knowledge Card](https://github.com/BunsenFeng/Knowledge_Card) for more details.

#### utils.py
Code for data process, which you can run as:
```bash
python code/utils.py list2pair \
    --input_file path/to/your/input.jsonl \
    --output_file path/to/your/output.jsonl \
    --func knowledge_card
```
Here are 4 main functions:
- list2pair: Only for the process of knowledge card generation
- process_by_line: Process the LLM generation
- merge_files: Merge files. For example, merge the two check results or merge the references generated by knowldge models
- pair_merge: Filter the useful references.

#### KG_mapping.py
Code for KG enhance, which you can run as:
```bash
python code/KG_mapping.py \
    --device 0 \
    --spacy_model en_core_web_md \
    --command el \
    --input_file path/to/input.jsonl \
    --output_file path/to/output_el.jsonl \
    --src_key question \
    --tgt_key question_entity \
    --question_type open \
    --ner_flag
```
Here are 4 main functions:
- el: Entity linking.
- entity_map: Map the entity string to entity id.
- convert_triple: Predict the related relation.
- expand entity: Merge the related neighbor entities.

#### score.py
! Please run this code under the folder of [kge](https://github.com/uma-pi1/kge)

Code for KGE score and prediction, which you can run as:
```bash
python code/score.py score \ # score or predict
    --input_file path/to/input.jsonl \
    --output_file path/to/output_el.jsonl \
```
Here are 2 main functions:
- score: Score the triple. Used in our KG factual check.
- predict: Predict related entity. Used in KG-enhanced query.

#### wikidata_query.py & tail_map.py
Query the entity info. As KGE model just pred the id, but no text information.

## Run
*A bit complicated, we'll simplify it in the coming months.* 

The specific code execution sequence is as follows：
1. Generate answer
- LLM QA: `main.py --rag` to get answer
- KG factual check: `main.py --extract_triple` to get text triple, `utils.py process_by_line` to phrase the llm output, `KG_mapping.py entity_map` to get triple id, `score.py score` to get triple score

2. Reference Generation
- (Query Generation: `main.py --generate_quesiotn` to get new query.)
- Query enhanced with KG: `KG_mapping.py el --src_key query` to get entities in query, `wikidata_query.py` to get the triples of entity, `KG_mapping.py conver_triple` to get related relation, `score.py predict` to predict the useful entity id, `tail_map.py` to get the information of useful entiy, `KG_mapping.py --expand_entity` to incorporate the entities.
- Reference Generation: `main.py --generate_reference` to get LLM reference. `card_infer.py` to get knowledge card reference. `utils.py` to unify their format.

3. Reference Filter
- Relevance check: `main.py --local_check` for llm relevance check, `utils.py process_by_line` for prhase llm output.
- KG factual check: the same in Generate answer
- Reference check: `utils.py --merge_files` to merge result, `utils,py --pair_merge` to filter the reference. `utils.py` to concat old references.

## Evaluation
For [hotpotQA](https://github.com/hotpotqa/hotpot) and [2wikimultihopQA](https://github.com/Alab-NII/2wikimultihop), we use the the official evaluation. Please see the evaluation in their repo.

For PopQA, we process the PopQA data into 2wikimultihopQA form and test it with the officail evaluation of 2wikimultihopQA.